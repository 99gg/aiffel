{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6-1. 프로젝트: CutMix 또는 Mixup 비교실험 하기\n",
    "\n",
    "지금까지 기본적인 augmentation 방법을 적용해 모델을 훈련시키고, 최신 augmentation 기법을 배워 보았습니다.\n",
    "\n",
    "이번에는 최신 기법(CutMix 또는 Mixup)을 적용해 모델을 훈련시켜 봅시다. 데이터셋에 두 가지 방법 중 하나를 적용하고, 모델을 학습시켜 주세요. 결과를 수치화하고 비교하는 것도 잊지 마세요!\n",
    "\n",
    "우선 주요 라이브러리 버전을 확인해 볼까요?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n",
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터셋에서 이미지 2개를 가져옵니다.\n",
    "for i, (image, label) in enumerate(ds_train_no_aug.take(1)):\n",
    "    if i == 0:\n",
    "        image_a = image[0]\n",
    "        label_a = label[0]\n",
    "        image_b = image[1]\n",
    "        label_b = label[1]\n",
    "        break\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image_a)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(image_b)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_clip_box(image):\n",
    "    # image.shape = (height, width, channel)\n",
    "    image_size_x = image.shape[1]\n",
    "    image_size_y = image.shape[0]\n",
    "\n",
    "    # get center of box\n",
    "    x = tf.cast(tf.random.uniform([], 0, image_size_x), tf.int32)\n",
    "    y = tf.cast(tf.random.uniform([], 0, image_size_y), tf.int32)\n",
    "\n",
    "    # get width, height of box\n",
    "    width = tf.cast(\n",
    "        image_size_x * tf.math.sqrt(1 - tf.random.uniform([], 0, 1)), tf.int32\n",
    "    )\n",
    "    height = tf.cast(\n",
    "        image_size_y * tf.math.sqrt(1 - tf.random.uniform([], 0, 1)), tf.int32\n",
    "    )\n",
    "\n",
    "    # clip box in image and get minmax box\n",
    "    x_min = tf.math.maximum(0, x - width // 2)\n",
    "    y_min = tf.math.maximum(0, y - height // 2)\n",
    "    x_max = tf.math.minimum(image_size_x, x + width // 2)\n",
    "    y_max = tf.math.minimum(image_size_y, y + height // 2)\n",
    "\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "\n",
    "# mix two images\n",
    "def mix_2_images(image_a, image_b, x_min, y_min, x_max, y_max):\n",
    "    image_size_x = image_a.shape[1]\n",
    "    image_size_y = image_a.shape[0]\n",
    "    middle_left = image_a[y_min:y_max, 0:x_min, :]  # image_b의 왼쪽 바깥 영역\n",
    "    middle_center = image_b[y_min:y_max, x_min:x_max, :]  # image_b의 안쪽 영역\n",
    "    middle_right = image_a[\n",
    "        y_min:y_max, x_max:image_size_x, :\n",
    "    ]  # image_b의 오른쪽 바깥 영역\n",
    "    middle = tf.concat([middle_left, middle_center, middle_right], axis=1)\n",
    "    top = image_a[0:y_min, :, :]\n",
    "    bottom = image_a[y_max:image_size_y, :, :]\n",
    "    mixed_img = tf.concat([top, middle, bottom], axis=0)\n",
    "\n",
    "    return mixed_img\n",
    "\n",
    "\n",
    "mixed_img = mix_2_images(image_a, image_b, x_min, y_min, x_max, y_max)\n",
    "plt.imshow(mixed_img.numpy())\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# mix two labels\n",
    "def mix_2_labels(image, label_a, label_b, x_min, y_min, x_max, y_max, num_classes=120):\n",
    "    image_size_x = image.shape[1]\n",
    "    image_size_y = image.shape[0]\n",
    "    mixed_area = (x_max - x_min) * (y_max - y_min)\n",
    "    total_area = image_size_x * image_size_y\n",
    "    ratio = tf.cast(mixed_area / total_area, tf.float32)\n",
    "\n",
    "    if len(label_a.shape) == 0:\n",
    "        label_a = tf.one_hot(label_a, num_classes)\n",
    "    if len(label_b.shape) == 0:\n",
    "        label_b = tf.one_hot(label_b, num_classes)\n",
    "    mixed_label = (1 - ratio) * label_a + ratio * label_b\n",
    "    return mixed_label\n",
    "\n",
    "\n",
    "mixed_label = mix_2_labels(label_a, label_b, x_min, y_min, x_max, y_max)\n",
    "print(mixed_label)\n",
    "\n",
    "# cutmix\n",
    "\n",
    "\n",
    "def cutmix(image, label, prob=1.0, batch_size=16, img_size=224, num_classes=120):\n",
    "    mixed_imgs = []\n",
    "    mixed_labels = []\n",
    " \n",
    "    for i in range(batch_size):\n",
    "        image_a = image[i]\n",
    "        label_a = label[i]\n",
    "        j = tf.cast(tf.random.uniform([], 0, batch_size), tf.int32)\n",
    "        image_b = image[j]\n",
    "        label_b = label[j]\n",
    "        x_min, y_min, x_max, y_max = get_clip_box(image_a, image_b)\n",
    "        mixed_imgs.append(mix_2_images(image_a, image_b, x_min, y_min, x_max, y_max))\n",
    "        mixed_labels.append(mix_2_labels(label_a, label_b, x_min, y_min, x_max, y_max))\n",
    "\n",
    "    mixed_imgs = tf.reshape(tf.stack(mixed_imgs), (batch_size, img_size, img_size, 3))\n",
    "    mixed_labels = tf.reshape(tf.stack(mixed_labels), (batch_size, num_classes))\n",
    "    return mixed_imgs, mixed_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    # Normalizes images: `uint8` -> `float32`\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.clip_by_value(image, 0, 1)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# def onehot(image, label):\n",
    "#     label = tf.one_hot(label, num_classes)\n",
    "#     return image, label\n",
    "\n",
    "\n",
    "def apply_normalize_on_dataset(\n",
    "    ds, is_test=False, batch_size=16, with_aug=False, with_cutmix=False\n",
    "):\n",
    "    ds = ds.map(normalize_and_resize_img, num_parallel_calls=2)\n",
    "    if not is_test and with_aug:\n",
    "        ds = ds.map(augment)\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test and with_cutmix:\n",
    "        ds = ds.map(cutmix, num_parallel_calls=2)\n",
    "    # else:\n",
    "    #     ds = ds.map(onehot, num_parallel_calls=2)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "print(\"=3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    \"stanford_dogs\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    as_supervised=False,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
